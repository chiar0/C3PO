# Choose: 'ollama' or 'openai'
llm.provider=ollama

# Ollama Configuration
llm.ollama.host=http://localhost:11434
llm.ollama.model=qwen3:4b-fp16

# OpenAI Configuration
llm.openai.api-key=